经验结论：
一般情况下，OOM的原因都是数据倾斜导致的
查看任务  -》 查看stage -》 查看执行特别慢的stage -》 查看导致数据倾斜的数据分布情况


注意：
需要处理的数据倾斜问题就是Shuffle后数据的分布是否均匀问题  
只要保证最后的结果是正确的，可以采用任何方式来处理数据倾斜，只要保证在处理过程中不发生数据倾斜就可以 

数据倾斜处理方法：   根本你是让key多分配到不同的task
1. 根源上解决数据倾斜：对倾斜的数据进行预处理，kafka数据分发尽量平均分配 彻底避免了shuffle类算子数据倾斜的问题

2. 调整并行度：增加shuffle  read task的数量，让原本分给一个task的多个key分配到多个task，这样每个task处理的数据就相对的少了些
只能缓解数据倾斜问题，治标不治本（某个key的数量远大于其他key，增加task是无法处理的）

3. 自定义partitioner: 适用场景大量不同的key被分配到了相同task造成该task数据量过大
使用自定义的partitioner代替默认的hashpartitioner
适合场景：只能将不同的key分散开，对同一个大key不适用
4. join操作:大小数据集的join操作   reduce side join改为map side join
 广播变量
 
5. 聚合操作中，数据集中分布的数据不均匀  reducebykey
两阶段聚合（局部聚合+全局聚合）
将原本相同的key通过附加随机前缀的方式，变成多个不同的key，就可以让原本被一个task处理的数据分散到多个task上去做局部聚合，
进而解决单个task处理数据量过多的问题。接着去除掉随机前缀，再次进行全局聚合  

6. join操作中，两个表都比较大，只有几个key数据分布不均匀
将有数据倾斜的RDD中倾斜Key对应的数据集单独抽取出来加上随机前缀，另外一个RDD每条数据分别与随机前缀结合形成新的RDD
（笛卡尔积，相当于将其数据增到到原来的N倍，N即为随机前缀的总个数），然后将二者Join后去掉前缀。然后将不包含倾斜Key的剩余数据进行Join。
最后将两次Join的结果集通过union合并，即可得到全部Join结果。   

7. JOIN操作中，两个数据集都比较大，有很多key的数据分布不均匀
`解决方案`：随机前缀和扩容RDD进行join  
`适用场景`：如果在进行join操作时，RDD中有大量的key导致数据倾斜，那么进行分拆key也没什么意义。  
`实现思路`：将该RDD的每条数据都打上一个n以内的随机前缀。同时对另外一个正常的RDD进行扩容，将每条数据都扩容成n条数据，
扩容出来的每条数据都依次打上一个0~n的前缀。最后将两个处理后的RDD进行join即可。和上一种方案是尽量只对少数倾斜key对应的数据进行特殊处理，
由于处理过程需要扩容RDD，因此上一种方案扩容RDD后对内存的占用并不大；而这一种方案是针对有大量倾斜key的情况，没法将部分key拆分出来进行单独处理，
因此只能对整个RDD进行数据扩容，对内存资源要求很高。  
`优点`：对join类型的数据倾斜基本都可以处理，而且效果也相对比较显著，性能提升效果非常不错。   
`缺点`：该方案更多的是缓解数据倾斜，而不是彻底避免数据倾斜。而且需要对整个RDD进行扩容，对内存资源要求很高。   
